\section{Methods} \label{sec:methods}
There exist many methods for solving the Schr\"odinger equation. Some of them are exact, but always heavy to deal with. Other are approximation, but hopefully not that expensive. We are going to look at \textit{Configuration Interaction} (CI), which in principle gives the exact energy (then called \textit{Full Configuration Interaction }(FCI)) and \textit{Hartree-Fock}, which is a mean field theory and will not give exact results.

\subsection{Configuration Interaction (CI)}
Often, we know the true wavefunctions $\ket{\Phi_i}$ in the external potential, but are off when interaction is added
\begin{equation}
\hat{H}_0\ket{\Phi_i}=\varepsilon_i\ket{\Phi_i},\qquad (\hat{H}_0+\hat{H}_I)\ket{\Phi_i}\neq\varepsilon_i\ket{\Phi_i}.
\end{equation}
However, the SDs form a ket basis, meaning we can write out eigenstates of $\hat{H}_I$ as a linear combination of the SDs
\begin{align}
\ket{\Psi_0}&=C_0^{(0)}\ket{\Phi_0}+C_1^{(0)}\ket{\Phi_1}+\hdots+C_{N-1}^{(0)}\ket{\Phi_{N-1}}\notag\\
\ket{\Psi_1}&=C_0^{(1)}\ket{\Phi_0}+C_1^{(1)}\ket{\Phi_1}+\hdots+C_{N-1}^{(1)}\ket{\Phi_{N-1}}\notag\\
\ket{\Psi_2}&=C_0^{(2)}\ket{\Phi_0}+C_1^{(2)}\ket{\Phi_1}+\hdots+C_{N-1}^{(2)}\ket{\Phi_{N-1}}\\
&\vdots\qquad\vdots\qquad\vdots\notag\\
\ket{\Psi_{N-1}}&=C_0^{(N-1)}\ket{\Phi_0}+C_1^{(N-1)}\ket{\Phi_1}+\hdots+C_N^{(N-1)}\ket{\Phi_{N-1}}.\notag
\end{align}
such that 
\begin{equation}
\hat{H}\ket{\Psi_p}=\varepsilon_p\ket{\Psi_p}.
\end{equation}
The Hamiltonian can be rewritten as a double sum over all states using the so-called \textit{completeness relation}, 
\begin{equation}
\hat{H}=\sum_{ij}\ket{\Phi_i}\mel{\Phi_i}{\hat{H}}{\Phi_j}\bra{\Phi_j}
\end{equation}
such that the Schr\"odinger equation can be rewritten as
\begin{equation}
\begin{pmatrix}
\mel{\Phi_0}{\hat{H}}{\Phi_0} & \mel{\Phi_0}{\hat{H}}{\Phi_1} & \hdots & \mel{\Phi_0}{\hat{H}}{\Phi_{N-1}}\\
\mel{\Phi_1}{\hat{H}}{\Phi_0} & \mel{\Phi_1}{\hat{H}}{\Phi_1} & \hdots & \mel{\Phi_1}{\hat{H}}{\Phi_{N-1}}\\
\vdots & \vdots & \ddots & \vdots\\
\mel{\Phi_{N-1}}{\hat{H}}{\Phi_0} & \mel{\Phi_{N-1}}{\hat{H}}{\Phi_1} & \hdots & \mel{\Phi_{N-1}}{\hat{H}}{\Phi_{N-1}}\\
\end{pmatrix}
\begin{pmatrix}
c_0^{(p)}\\ c_1^{(p)} \\ \vdots\\ c_{N-1}^{(p)}
\end{pmatrix}
=\varepsilon_p
\begin{pmatrix}
c_0^{(p)}\\ c_1^{(p)} \\ \vdots\\ c_{N-1}^{(p)}
\end{pmatrix}
\label{eq:CIS_matrix}
\end{equation}

Until now, we have not made any assumptions, such that the equation above will give exact results when all SPFs are included. The problem is that the matrix scales so badly, the number of Slater Determinant that we need to include goes as 
\begin{equation}
N_{\text{FCI}}=\binom{N_{\text{single orbitals}}}{N_{\text{electrons}}}
\end{equation}
which is exploding. This is quite annoying since we in principle know how to solve the problems exact. However, in this project we restrict ourselves to three orbitals and single excitations only, which makes the problem more manageable. [https://github.com/ManyBodyPhysics/FYS4480/blob/master/doc/Exercises/Answers/FirstsetAnswer.pdf]The matrices are given in results, and a program calculating solutions to equation (\ref{eq:c_H_c}-\ref{eq:ia_H_jb}) is outlined below

\lstset{basicstyle=\scriptsize}
\begin{lstlisting}
class CIS:
  '''Configuration Interction Singles class for atomic structure'''

  def __init__(self, Z, basis):

    self.elem = Integrals(Z,basis)  # Matrix elements/integrals
    self.n = Z                      # Assume neutral atom


  def c_H_c(self):
    '''Reference energy'''

    OBT = 0
    for i in range(self.n):
      OBT += self.elem.OBME(i,i)
    TBT = 0
    for i in range(self.n):
      for j in range(self.n):
        TBT += 0.5*self.elem.AS(i,j,i,j)
    return OBT + TBT


  def c_H_ia(self, i,a):
    '''Singly excited ket'''

    OBT = self.elem.OBME(i,a)
    TBT = 0
    for j in range(self.n):
      TBT += self.elem.AS(a,j,i,j)
    return OBT + TBT


  def ia_H_jb(self, i,a,j,b):
    '''Singly excited bra and ket'''

    Result = self.elem.AS(a,j,i,b)
    if a==b:
    Result -= self.elem.OBME(i,j)
    for k in range(self.n):
      Result -= self.elem.AS(i,k,j,k)
      if i==j:
        for l in range(self.n):
          Result += self.elem.OBME(l,l)
          for m in range(self.n):
            Result += 0.5*self.elem.AS(l,m,l,m)
    if i==j:
      Result += self.elem.OBME(a,b)
      for k in range(self.n):
        Result += self.elem.AS(a,k,b,k)
    return Result
\end{lstlisting}

\subsection{Hartree-Fock}
When we calculated the reference energy above, our basis contained only one Slater determinant, more specifically the ground state. In Hartree-Fock, we still have a single Slater determinant basis, but we now construct new SPFs with the constraint of minimizing the energy. 

In general, one can change from one single-particle basis to another by a unitary transform,
\begin{equation}
\ket{p}=\sum_{\alpha}c_{p\alpha}\ket{\alpha},
\end{equation}
where we use greek letters for the old basis and roman letters for the new one. If we then insert into \eqref{eq:c_H_c}, we get a find energy formula with coefficients, $C_{p\lambda}$, that we can vary
\begin{equation}
E=\sum_{p}^N\sum_{\alpha\beta}C_{p\alpha}^*C_{p\beta}\mel{\alpha}{\hat{h}_0}{\beta}+\frac{1}{2}
\sum_{pq}^N\sum_{\alpha\beta\gamma\delta}C_{p\alpha}^*C_{q\beta}^*C_{p\gamma}C_{q\delta}\mel{\alpha\beta}{\hat{v}}{\gamma\delta}_{\text{AS}}.
\end{equation}
Further, we assume that also our new basis is orthonormal, i.e,
\begin{align}
\braket{p}{q}&=\sum_{\alpha}c_{p\alpha}^*c_{q\alpha}\braket{\alpha}{\alpha}=\sum_{\alpha}c_{p\alpha}^*c_{q\alpha}=\delta_{pq}\\
&\Rightarrow\sum_{\alpha}c_{p\alpha}^*c_{q\alpha}-\delta_{pq}=0\label{eq:constraint}
\end{align}

We now have a function, $E$, that we want to minimize with respect to a constraint given in equation \eqref{eq:constraint}. This is a typical situation where Lagrange Multipliers is convenient to use, which in this case can be written as
\begin{equation}
{\cal L}(\{C_{p\alpha}\})=E(\{C_{p\alpha}\})-\sum_a\varepsilon_a\Big(\sum_{\alpha}c_{p\alpha}^*c_{q\alpha}-\delta_{pq}\Big).
\end{equation}
The variation in reference energy is then find to be
\begin{equation}
\delta E=\sum_{k\alpha}\frac{\partial E}{\partial C_{k\alpha}^*}\delta C_{k\alpha}^*+\sum_{k\alpha}\frac{\partial E}{\partial C_{k\alpha}}\delta C_{k\alpha}-\sum_{k\alpha}\varepsilon_k(C_{k\alpha}\delta C_{k\alpha}^*+C_{k\alpha}^*\delta C_{k\alpha})
\label{eq:E_hf}
\end{equation}
which is zero when $E$ is minimized. Each coefficient $C_{k\alpha}$ and $C_{k\alpha}^*$ is independent, so they can be varied independently. Thus
\begin{equation}
\bigg(\frac{\partial E}{\partial C_{k\alpha}^*}-\varepsilon_kC_{k\alpha}\bigg)\delta C_{k\alpha}^*=0,
\end{equation}
which is satisfied if and only if
\begin{equation}
\frac{\partial E}{\partial C_{k\alpha}^*}-\varepsilon_kC_{k\alpha}=0\qquad\forall\,\,\, k,\alpha
\end{equation}
The first term can be derived from \eqref{eq:E_hf}, and reads
\begin{equation}
\frac{\partial E}{\partial C_{k\alpha}^*}=\sum_{\beta}C_{k\beta}\mel{\alpha}{\hat{h}_0}{\beta}+\sum_p^N\sum_{\beta\gamma\delta}C_{p\beta}^*C_{k\gamma}C_{p\delta}\mel{\alpha\beta}{\hat{v}}{\gamma\delta}_{\text{AS}}.
\end{equation}
This results in the equation
\begin{equation}
\sum_{\gamma}\hat{h}_{\alpha\gamma}^{\text{HF}}C_{k\gamma}=\varepsilon_kC_{k\gamma}
\label{eq:HF_sum}
\end{equation}
where we have defined
\begin{equation}
\hat{h}_{\alpha\gamma}^{\text{HF}}\equiv\mel{\alpha}{\hat{h}_0}{\gamma}+\sum_p^N\sum_{\beta\delta}C_{p\beta}^*C_{p\delta}\mel{\alpha\beta}{\hat{v}}{\gamma\delta}_{\text{AS}}.
\end{equation}
We recognize that \eqref{eq:HF_sum} can be written as a matrix-vector product
\begin{equation}
\hat{h}^{\text{HF}}C_k=\varepsilon_k^{\text{HF}}C_k
\end{equation}
where $C_k$ are columns in our coefficient matrix and $\varepsilon_k^{\text{HF}}$ are just the eigenvalues of $\hat{h}^{\text{HF}}$, they have no physical significance. We will use this equation to find the optimal SPFs (optimal $C_k$'s) and then find the energy from equation \eqref{eq:E_hf}.
\begin{equation}
\hat{h}^{\text{HF}}(C_k^{i+1})C_k^i=\varepsilon_k^{\text{HF}}C_k^i
\label{eq:HF_iter}
\end{equation}
Usually one initialize this with $\hat{C}=\hat{{\cal I}}$, the identity matrix.

The implementation could look something like this
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}
class HF:
  '''Hartree-Fock class for atomic structure'''

  def __init__(self, Z, basis):

    self.elem = Integrals(Z,basis)  # Matrix elements/integrals
    self.n = Z                      # Number of electrons, assuming neutral atom
    self.N = len(basis)             # Number of states


  def HF_elements(self,i,j,C):
    '''HF matrix elements (i,j)'''

    Result = self.elem.OBME(i, j)
    for p in range(self.n):
      for c in range(self.N):
        for d in range(self.N):
          Result += C[p,c]*C[p,d]*self.elem.AS(i,c,j,d)
    return Result


  def HF_matrix(self,C):
    '''HF-matrix'''

    HF_mat = np.empty((self.N,self.N))
    for i in range(self.N):
      for j in range(self.N):
        HF_mat[i,j] = HF.HF_elements(self,i,j,C)
    return HF_mat


  def HF_iter(self,tol=1e-8,max_iter=50):
    '''Solving HF with an iterative scheme'''

    C = np.eye(self.N)
    eps = np.ones(self.N)
    for i in range(max_iter):
      HF_mat = HF.HF_matrix(self,C)
      eps_new, C = np.linalg.eigh(HF_mat)
      C = C.T

      if abs(eps[0]-eps_new[0]) < tol:
        break
        eps = eps_new
    return HF.calc_E(self,C), i


  def calc_E(self,C):
    '''Calculate energy'''

    E = 0
    for p in range(self.n):
      for a in range(self.N):
        for b in range(self.N):
          E += C[p,a]*C[p,b]*self.elem.OBME(a,b)
          for q in range(self.n):
            for c in range(self.N):
              for d in range(self.N):
                E += 0.5*C[p,a]*C[q,b]*C[p,c]*C[q,d]*self.elem.AS(a,b,c,d)
    return E
\end{lstlisting}
